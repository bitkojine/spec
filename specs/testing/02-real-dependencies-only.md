# No-Test-Doubles Engineering Specification

## 1. Overview

This specification establishes a strict policy prohibiting the use of test doubles within the engineering organization. The primary objective is to maximize the realism and reliability of automated test suites by ensuring that every component of the system under test (SUT) and its dependencies are real, production-grade implementations.

This policy is designed to eliminate the inherent risks of artificial test behavior, reduce the maintenance burden associated with brittle mocking structures, and provide the highest possible confidence that the software will behave correctly in production environments.

## 2. Applicability to Coding Agents

This specification applies to all tests within the repository, with a mandatory requirement for **automated coding agents**.
* Coding agents MUST generate tests that comply strictly with this policy.
* Non-compliant tests (those utilizing test doubles) generated by agents are considered fundamentally invalid and MUST be rejected during automated or manual review.

## 3. Definitions

* **Test Double**: Any implementation used in place of a real component for testing purposes, including but not limited to:
    * **Mock**: Objects pre-programmed with expectations which form a specification of the calls they are expected to receive.
    * **Stub**: Objects providing canned answers to calls made during the test.
    * **Spy**: Objects that record some information based on how they were called.
    * **Fake**: Objects that actually have working implementations, but usually take some shortcut which makes them not suitable for production (e.g., an in-memory database that is not a real instance of the production engine).
    * **Simulator**: A high-level software implementation that mimics the behavior of a complex hardware or software system.
* **System Under Test (SUT)**: The specific class, function, or module being validated by a test.
* **Real Implementation**: The actual code, service, or dependency intended for production use.
* **Production-Grade**: Software and configurations that meet the standards for stability, performance, and correctness required for live environment operations.

## 4. Normative Rules

### 4.1. Prohibition of Test Doubles
* Test doubles of any kind MUST NOT be used.
* Tests MUST NOT introduce artificial behavior or replace real components with substitute implementations.

### 4.2. Direct Behavior Validation
* Generated tests MUST validate the behavior of the system under test directly.
* Tests MUST NOT assert on internal wiring, call counts (e.g., `toHaveBeenCalledWith`), or the interactions between the SUT and its dependencies.
* Assertions MUST be made only on the public outputs, state changes, or side effects of the SUT.

### 4.3. Mandatory Use of Real Dependencies
* Every dependency involved in a test MUST be a real, production-grade implementation.
* Configuration may vary between testing and production (e.g., connection strings, credentials), but the underlying code/engine MUST NOT vary.
* In-memory, ephemeral, or local versions of real systems (e.g., SQLite for local DB testing if the engine is identical, or a Dockerized instance of the production database) are acceptable **only if** they are behaviorally identical to the production systems.

### 4.4. Boundary Constraints
* Tests MUST NOT attempt to "mock the boundary" of the system. If a test reaches a boundary with an external service, that service MUST be represented by a real instance or a behaviorally identical local version.

## 5. Rationale

### Correctness and Realism
Mocks often fail to adapt to changes in the real implementation's behavior. A suite that passes with mocks can still fail in production because the mocks were based on incorrect or outdated assumptions about how real components behave.

### Confidence
The ultimate goal of testing is to provide confidence to deploy. Confidence is highest when the test environment most closely mirrors the production environment.

### Reducing Brittleness
Interaction-based tests (asserting on *how* a component calls another) are notoriously brittle. They often break during internal refactorings that do not change external behavior. By focusing on real implementations and outcomes, tests remain stable during refactoring.

## 6. Non-Goals

* **Isolated Unit Test Speed**: This policy prioritizes correctness over the micro-optimization of individual test execution speed.
* **Interaction-Based Testing**: Validating the internal communication protocols between components is explicitly secondary to validating the final system state/output.

## 7. Examples

### 7.1. Prohibited Patterns

#### Mocking a Database Dependency
```typescript
// PROHIBITED: Mocking the database interface
const mockDb = { query: jest.fn().mockReturnValue([{ id: 1, name: 'Test' }]) };
const service = new UserService(mockDb);
const user = await service.getUser(1);
expect(mockDb.query).toHaveBeenCalledWith('SELECT * FROM users WHERE id = 1');
```

#### Stubbing an External API
```typescript
// PROHIBITED: Stubbing an HTTP client response
jest.spyOn(axios, 'get').mockResolvedValue({ data: { status: 'ok' } });
const result = await checkHealth();
expect(result).toBe('ok');
```

### 7.2. Compliant Patterns

#### Using a Real (Ephemeral) Database
```typescript
// COMPLIANT: Using a real, local database instance
const db = await createTestDatabase(); // Spin up real Postgres in Docker or in-memory identical engine
const service = new UserService(db);
const user = await service.getUser(1);
expect(user.name).toBe('Expected Name');
```

#### Using Real Service Instances
```typescript
// COMPLIANT: Instantiating real versions of all internal dependencies
const config = new RealConfig();
const logger = new RealLogger();
const authService = new RealAuthService(config, logger);
const controller = new UserController(authService);
const result = await controller.handleRequest(req);
expect(result.statusCode).toBe(200);
```

## 8. Enforcement Guidance

### Automated Enforcement
* Linting rules SHOULD be configured to detect and error on the usage of known mocking libraries (e.g., `jest.mock`, `sinon`, `testdouble`).
* CI pipelines MUST fail if any test file imports a prohibited mocking library.

### Human and Agent Review
* Reviewers MUST check for "hidden" test doubles, such as manual fake implementations defined within test files.
* Coding agents MUST be instructed to reject any instruction that requires the creation of a mock or stub.
